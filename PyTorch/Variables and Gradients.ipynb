{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables and Gradients\n",
    "\n",
    "## Variables\n",
    "     -  Wrapper around Tensor\n",
    "     -  Allows accumulation of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=Variable(torch.ones(2,2),requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.],\n",
       "        [ 1.,  1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  2.],\n",
      "        [ 2.,  2.]])\n",
      "tensor([[ 2.,  2.],\n",
      "        [ 2.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "b=Variable(torch.ones(2,2),requires_grad=True)\n",
    "print(a+b)\n",
    "print(torch.add(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "print(a*b)\n",
    "print(torch.mul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients\n",
    "**requires_grad**\n",
    "* Allows calculation of gradients w.r.t the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{i}=5(x_{i}+1)^{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x=Variable(torch.ones(2),requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{i}\\big\\rvert_{x_{i}=1} = 5(1+1)^{2}=5(2)^{2}=5(4)=20$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 20.,  20.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 5 * (x+1) ** 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t variable)\n",
    "* Thus reducing y to scalar then\n",
    "\n",
    "$$o=\\frac{1}{2}\\sum_{i}y_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=(1/2)*torch.sum(y)\n",
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap y equation:**$$ y_{i}=5(x_{i}+1)^{2} $$\n",
    "**Recap o equation:** $$o=\\frac{1}{2}\\sum_{i}y_{i}$$\n",
    "**Substitute y into o equation:** $$o=\\frac{1}{2}\\sum_{i}5(x_{i}+1)^{2}$$\n",
    "\n",
    "$$\\frac{\\partial{o}}{\\partial{x_{i}}}=\\frac{1}{2}[10(x_{i}+1)]$$\n",
    "\n",
    "$$\\frac{\\partial{o}}{\\partial{x_{i}}}\\bigg\\rvert_{x_{i}=1}=\\frac{1}{2}[10(1+1)]=10 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward(retain_graph=True)\n",
    "#Calculates the gradients given x=1\n",
    "#Need to retain graph to run Backward the second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.,  10.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad #Gradient With Respect to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 20.,  20.])\n"
     ]
    }
   ],
   "source": [
    "o.backward(torch.FloatTensor([1.0,1.0]),retain_graph=True) #Putting x1=1 and x2=1\n",
    "print(x.grad) #Each time you run backwards, it calculates gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
